#!/usr/bin/env python3
"""
çœŸå®è®­ç»ƒåœºæ™¯çš„å®Œæ•´æµ‹è¯•
æ¨¡æ‹ŸçœŸå®çš„è®­ç»ƒå¾ªç¯ï¼ŒåŒ…æ‹¬æ•°æ®åŠ è½½ã€æ‰¹æ¬¡å¤„ç†ã€æ€§èƒ½ç»Ÿè®¡ç­‰
"""

import sys
import os
sys.path.append('src')

import argparse
import torch
import time
import numpy as np
from collections import defaultdict
from src.data.dataset import get_model_dataset
from src.data.data_loader import get_data_loaders
from src.data.transforms import get_default_transform

class TrainingStats:
    """è®­ç»ƒç»Ÿè®¡ç±»"""
    
    def __init__(self):
        self.reset()
    
    def reset(self):
        self.batch_times = []
        self.batch_sizes = []
        self.protein_atom_counts = []
        self.ligand_atom_counts = []
        self.success_count = 0
        self.error_count = 0
        self.start_time = None
        self.end_time = None
    
    def add_batch(self, batch, batch_time, success=True):
        if success:
            self.success_count += 1
            self.batch_times.append(batch_time)
            
            if batch is not None:
                if hasattr(batch, 'num_graphs'):
                    self.batch_sizes.append(batch.num_graphs)
                
                if hasattr(batch, 'protein_pos') and batch.protein_pos is not None:
                    self.protein_atom_counts.append(batch.protein_pos.shape[0])
                
                if hasattr(batch, 'ligand_pos') and batch.ligand_pos is not None:
                    self.ligand_atom_counts.append(batch.ligand_pos.shape[0])
        else:
            self.error_count += 1
    
    def get_stats(self):
        if not self.batch_times:
            return {
                'total_batches': self.success_count + self.error_count,
                'success_count': self.success_count,
                'error_count': self.error_count,
                'success_rate': 0.0,
                'avg_batch_time': 0.0,
                'total_time': 0.0
            }
        
        return {
            'total_batches': self.success_count + self.error_count,
            'success_count': self.success_count,
            'error_count': self.error_count,
            'success_rate': self.success_count / (self.success_count + self.error_count) * 100,
            'avg_batch_time': np.mean(self.batch_times),
            'total_time': self.end_time - self.start_time if self.end_time and self.start_time else 0,
            'avg_batch_size': np.mean(self.batch_sizes) if self.batch_sizes else 0,
            'avg_protein_atoms': np.mean(self.protein_atom_counts) if self.protein_atom_counts else 0,
            'avg_ligand_atoms': np.mean(self.ligand_atom_counts) if self.ligand_atom_counts else 0
        }

def test_real_training_scenario():
    """æµ‹è¯•çœŸå®è®­ç»ƒåœºæ™¯"""
    print("ğŸš€ å¼€å§‹çœŸå®è®­ç»ƒåœºæ™¯æµ‹è¯•...")
    
    # è®­ç»ƒé…ç½®
    TRAINING_CONFIG = {
        'dataset_path': 'src/data/crossdocked_v1.1_rmsd1.0_processed',
        'split_file': 'src/data/split_by_name.pt',
        'batch_size': 32,
        'num_workers': 0,  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
        'shuffle_train': True,
        'shuffle_test': False,
        'test_batches': 100,  # æµ‹è¯•çš„æ‰¹æ¬¡æ•°é‡
        'val_batches': 50
    }
    
    print("ğŸ“Š è®­ç»ƒé…ç½®:")
    for key, value in TRAINING_CONFIG.items():
        print(f"   {key}: {value}")
    
    # åˆ›å»ºé…ç½®å¯¹è±¡
    config = argparse.Namespace(
        name='crossdocked',
        path=TRAINING_CONFIG['dataset_path'],
        split=TRAINING_CONFIG['split_file'],
        mode='full',
        version='ref_prior_aromatic'
    )
    
    print("\nğŸ”§ åˆ›å»ºçœŸå®è®­ç»ƒDataLoader...")
    
    try:
        # è·å–æ•°æ®åŠ è½½å™¨
        data_loaders = get_data_loaders(
            dataset_path=TRAINING_CONFIG['dataset_path'],
            batch_size=TRAINING_CONFIG['batch_size'],
            num_workers=TRAINING_CONFIG['num_workers'],
            split_file=TRAINING_CONFIG['split_file'],
            shuffle_train=TRAINING_CONFIG['shuffle_train'],
            shuffle_test=TRAINING_CONFIG['shuffle_test']
        )
        
        print(f"âœ… DataLoaderåˆ›å»ºæˆåŠŸ")
        print(f"   å¯ç”¨çš„åˆ†å‰²: {list(data_loaders.keys())}")
        
        for split_name, loader in data_loaders.items():
            print(f"   {split_name}: {len(loader)} ä¸ªæ‰¹æ¬¡")
        
    except Exception as e:
        print(f"âŒ DataLoaderåˆ›å»ºå¤±è´¥: {e}")
        return False
    
    print("\nğŸš€ å¼€å§‹æ¨¡æ‹ŸçœŸå®è®­ç»ƒå¾ªç¯...")
    
    # æµ‹è¯•è®­ç»ƒé›†
    if 'train' in data_loaders:
        train_stats = test_loader_performance(
            data_loaders['train'], 
            'TRAIN', 
            TRAINING_CONFIG['test_batches']
        )
        
        print(f"\nğŸ“Š TRAIN æ€§èƒ½ç»Ÿè®¡:")
        stats = train_stats.get_stats()
        for key, value in stats.items():
            if isinstance(value, float):
                print(f"   {key}: {value:.3f}")
            else:
                print(f"   {key}: {value}")
    
    # æµ‹è¯•éªŒè¯é›†
    if 'val' in data_loaders:
        val_stats = test_loader_performance(
            data_loaders['val'], 
            'VAL', 
            TRAINING_CONFIG['val_batches']
        )
        
        print(f"\nğŸ“Š VAL æ€§èƒ½ç»Ÿè®¡:")
        stats = val_stats.get_stats()
        for key, value in stats.items():
            if isinstance(value, float):
                print(f"   {key}: {value:.3f}")
            else:
                print(f"   {key}: {value}")
    
    # æµ‹è¯•æµ‹è¯•é›†
    if 'test' in data_loaders:
        test_stats = test_loader_performance(
            data_loaders['test'], 
            'TEST', 
            TRAINING_CONFIG['val_batches']
        )
        
        print(f"\nğŸ“Š TEST æ€§èƒ½ç»Ÿè®¡:")
        stats = test_stats.get_stats()
        for key, value in stats.items():
            if isinstance(value, float):
                print(f"   {key}: {value:.3f}")
            else:
                print(f"   {key}: {value}")
    
    print("\n" + "=" * 80)
    print("ğŸ‰ çœŸå®è®­ç»ƒåœºæ™¯æµ‹è¯•å®Œæˆ!")
    
    return True

def test_loader_performance(dataloader, split_name, total_batches):
    """æµ‹è¯•æ•°æ®åŠ è½½å™¨æ€§èƒ½"""
    stats = TrainingStats()
    stats.start_time = time.time()
    
    print(f"\nğŸ“ˆ æµ‹è¯•{split_name} DataLoader:")
    print(f"   {split_name}: æµ‹è¯• {total_batches} ä¸ªæ‰¹æ¬¡")
    
    batch_count = 0
    
    for batch_idx, batch in enumerate(dataloader):
        if batch_idx >= total_batches:
            break
        
        batch_start = time.time()
        
        try:
            # æ¨¡æ‹ŸçœŸå®è®­ç»ƒä¸­çš„æ‰¹æ¬¡å¤„ç†
            if batch is not None:
                # æ¨¡æ‹Ÿå‰å‘ä¼ æ’­
                if hasattr(batch, 'protein_pos') and batch.protein_pos is not None:
                    # æ¨¡æ‹Ÿå¯¹è›‹ç™½è´¨ä½ç½®çš„å¤„ç†
                    protein_center = batch.protein_pos.mean(dim=0, keepdim=True)
                
                if hasattr(batch, 'ligand_pos') and batch.ligand_pos is not None:
                    # æ¨¡æ‹Ÿå¯¹é…ä½“ä½ç½®çš„å¤„ç†
                    ligand_center = batch.ligand_pos.mean(dim=0, keepdim=True)
                
                # æ¨¡æ‹ŸæŸå¤±è®¡ç®—ï¼ˆç®€å•ç¤ºä¾‹ï¼‰
                if hasattr(batch, 'protein_pos') and hasattr(batch, 'ligand_pos'):
                    # è®¡ç®—è›‹ç™½è´¨å’Œé…ä½“ä¸­å¿ƒçš„è·ç¦»ä½œä¸ºç¤ºä¾‹
                    if batch.protein_pos.size(0) > 0 and batch.ligand_pos.size(0) > 0:
                        distance = torch.norm(protein_center - ligand_center)
                
                stats.add_batch(batch, time.time() - batch_start, success=True)
            else:
                stats.add_batch(None, time.time() - batch_start, success=False)
            
            batch_count += 1
            
            # æ¯10ä¸ªæ‰¹æ¬¡æŠ¥å‘Šä¸€æ¬¡è¿›åº¦
            if batch_count % 10 == 0:
                elapsed = time.time() - stats.start_time
                avg_time = elapsed / batch_count
                print(f"     æ‰¹æ¬¡ {batch_count}/{total_batches}: æˆåŠŸ={stats.success_count}, é”™è¯¯={stats.error_count}, å¹³å‡æ—¶é—´={avg_time:.3f}s")
        
        except Exception as e:
            stats.add_batch(None, time.time() - batch_start, success=False)
            batch_count += 1
            if batch_count <= 5:  # åªæ‰“å°å‰5ä¸ªé”™è¯¯
                print(f"     æ‰¹æ¬¡ {batch_count} å¤„ç†å¤±è´¥: {e}")
    
    stats.end_time = time.time()
    
    # æ‰“å°æœ€ç»ˆç»Ÿè®¡
    elapsed = stats.end_time - stats.start_time
    print(f"   Epoch 1 å®Œæˆ: {elapsed:.2f}s, {batch_count} æ‰¹æ¬¡")
    
    return stats

def test_data_quality():
    """æµ‹è¯•æ•°æ®è´¨é‡"""
    print("\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥...")
    
    try:
        # åŠ è½½æ•°æ®é›†
        config = argparse.Namespace(
            name='crossdocked',
            path='src/data/crossdocked_v1.1_rmsd1.0_processed',
            split='src/data/split_by_name.pt',
            mode='full',
            version='ref_prior_aromatic'
        )
        
        result = get_model_dataset(config)
        if isinstance(result, tuple):
            dataset, subsets = result
        else:
            dataset = result
        
        print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ: {len(dataset)} ä¸ªæ ·æœ¬")
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        sample_checks = []
        for i in range(min(100, len(dataset))):  # æ£€æŸ¥å‰100ä¸ªæ ·æœ¬
            try:
                sample = dataset[i]
                if sample is not None:
                    # æ£€æŸ¥å¿…è¦å±æ€§
                    has_protein_pos = hasattr(sample, 'protein_pos') and sample.protein_pos is not None
                    has_ligand_pos = hasattr(sample, 'ligand_pos') and sample.ligand_pos is not None
                    has_protein_feat = hasattr(sample, 'protein_atom_feature') and sample.protein_atom_feature is not None
                    has_ligand_feat = hasattr(sample, 'ligand_atom_feature') and sample.ligand_atom_feature is not None
                    
                    sample_checks.append({
                        'index': i,
                        'has_protein_pos': has_protein_pos,
                        'has_ligand_pos': has_ligand_pos,
                        'has_protein_feat': has_protein_feat,
                        'has_ligand_feat': has_ligand_feat,
                        'protein_atoms': sample.protein_pos.shape[0] if has_protein_pos else 0,
                        'ligand_atoms': sample.ligand_pos.shape[0] if has_ligand_pos else 0
                    })
                else:
                    sample_checks.append({'index': i, 'error': 'Failed to load'})
            except Exception as e:
                sample_checks.append({'index': i, 'error': str(e)})
        
        # ç»Ÿè®¡ç»“æœ
        valid_samples = [s for s in sample_checks if 'error' not in s]
        print(f"âœ… æ•°æ®è´¨é‡æ£€æŸ¥å®Œæˆ:")
        print(f"   æ£€æŸ¥æ ·æœ¬æ•°: {len(sample_checks)}")
        print(f"   æœ‰æ•ˆæ ·æœ¬æ•°: {len(valid_samples)}")
        
        if valid_samples:
            protein_atoms = [s['protein_atoms'] for s in valid_samples]
            ligand_atoms = [s['ligand_atoms'] for s in valid_samples]
            
            print(f"   å¹³å‡è›‹ç™½è´¨åŸå­æ•°: {np.mean(protein_atoms):.1f}")
            print(f"   å¹³å‡é…ä½“åŸå­æ•°: {np.mean(ligand_atoms):.1f}")
            print(f"   è›‹ç™½è´¨åŸå­æ•°èŒƒå›´: {min(protein_atoms)} - {max(protein_atoms)}")
            print(f"   é…ä½“åŸå­æ•°èŒƒå›´: {min(ligand_atoms)} - {max(ligand_atoms)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®è´¨é‡æ£€æŸ¥å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¥ å¼€å§‹çœŸå®è®­ç»ƒåœºæ™¯å®Œæ•´æµ‹è¯•...")
    
    success = True
    
    # 1. æ•°æ®è´¨é‡æ£€æŸ¥
    if not test_data_quality():
        success = False
    
    # 2. çœŸå®è®­ç»ƒåœºæ™¯æµ‹è¯•
    if not test_real_training_scenario():
        success = False
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå‡†å¤‡å°±ç»ªï¼")
        print("âœ… æ•°æ®åŠ è½½ç³»ç»Ÿæ­£å¸¸å·¥ä½œ")
        print("âœ… æ‰¹æ¬¡å¤„ç†æ€§èƒ½è‰¯å¥½")
        print("âœ… è®­ç»ƒå¾ªç¯æ¨¡æ‹ŸæˆåŠŸ")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥ï¼")
    
    return success

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
